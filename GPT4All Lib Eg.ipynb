{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a783a54-acb9-4713-a330-838a8568a7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpt4all\n",
    "import markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c932e9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = gpt4all.GPT4All.list_models()\n",
    "models = [\n",
    "    # finished\n",
    "    # {\"filename\": \"ggml-gpt4all-l13b-snoozy.bin\"},\n",
    "    # {\"filename\": \"ggml-mpt-7b-instruct.bin\"},\n",
    "    # {\"filename\": \"ggml-v3-13b-hermes-q5_1.bin\"},\n",
    "    {\"filename\": \"ggml-gpt4all-j-v1.3-groovy.bin\"},\n",
    "    # {\"filename\": \"ggml-mpt-7b-chat.bin\"},\n",
    "\n",
    "    # needed for download\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37e91400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  ../models/gpt4all/ggml-gpt4all-j-v1.3-groovy.bin\n",
      "gptj_model_load: loading model from '../models/gpt4all/ggml-gpt4all-j-v1.3-groovy.bin' - please wait ...\n",
      "gptj_model_load: n_vocab = 50400\n",
      "gptj_model_load: n_ctx   = 2048\n",
      "gptj_model_load: n_embd  = 4096\n",
      "gptj_model_load: n_head  = 16\n",
      "gptj_model_load: n_layer = 28\n",
      "gptj_model_load: n_rot   = 64\n",
      "gptj_model_load: f16     = 2\n",
      "gptj_model_load: ggml ctx size = 5401.45 MB\n",
      "gptj_model_load: kv self size  =  896.00 MB\n",
      "gptj_model_load: ................................... done\n",
      "gptj_model_load: model size =  3609.38 MB / num tensors = 285\n"
     ]
    }
   ],
   "source": [
    "MODELPATH = \"../models/gpt4all/\"\n",
    "for i in models:\n",
    "    gpt = gpt4all.GPT4All(i['filename'],MODELPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81d828de",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "### Instruction: \n",
    "You are OpenBrain, a large language model. Follow the user's instructions carefully. Markdown will be used to respond.\n",
    "### Prompt: \n",
    "\"\"\"\n",
    "\n",
    "blockMess = [{\"role\": \"system\", \"content\": f\"{prompt}\"}]\n",
    "class gpt4:\n",
    "    messages = blockMess\n",
    "    message = \"\"\n",
    "    response: dict = {}\n",
    "\n",
    "    def __init__(self):\n",
    "        self.prompt = self.messages\n",
    "        self.reset = True\n",
    "\n",
    "\n",
    "    # @staticmethod\n",
    "    def chat(self, prompt: dict, reset: bool, **generate_kwargs):\n",
    "        if(reset):\n",
    "            self.reset = reset\n",
    "            self.messages = blockMess\n",
    "            \n",
    "        for t in prompt:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": f\"{t}\"})\n",
    "\n",
    "        self.response = gpt.chat_completion(self.messages, default_prompt_header=False, streaming=True)\n",
    "        self.response[\"model\"] = 'gpt-4'\n",
    "\n",
    "        if self.response:\n",
    "            # print(self.response['choices'][0]['message']['content'])\n",
    "            self.message = self.response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c61efe34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction: \n",
      "You are OpenBrain, a large language model. Follow the user's instructions carefully. Markdown will be used to respond.\n",
      "### Prompt: \n",
      "\n",
      "\n",
      "Hello, how are you\n",
      "give me javascript code to print hello world\n",
      "### Response:\n",
      " \n",
      "Hello, I am OpenBrain and ready to assist you with your request. Here is the JavaScript code to print \"Hello, World!\":\n",
      "```javascript\n",
      "console.log(\"Hello, World!\"); // prints \"Hello, World!\" in the console\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "tasks = [\"Hello, how are you\",\"give me javascript code to print hello world\"]\n",
    "g = gpt4()\n",
    "\n",
    "g.chat(prompt=tasks, reset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e3d5c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'gpt-4',\n",
       " 'usage': {'prompt_tokens': 230,\n",
       "  'completion_tokens': 209,\n",
       "  'total_tokens': 439},\n",
       " 'choices': [{'message': {'role': 'assistant',\n",
       "    'content': ' \\nHello, I am OpenBrain and ready to assist you with your request. Here is the JavaScript code to print \"Hello, World!\":\\n```javascript\\nconsole.log(\"Hello, World!\"); // prints \"Hello, World!\" in the console\\n```'}}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bb92847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nHello, I am OpenBrain and ready to assist you with your request. Here is the JavaScript code to print \"Hello, World!\":\\n```javascript\\nconsole.log(\"Hello, World!\"); // prints \"Hello, World!\" in the console\\n```'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.message\n",
    "# markdown.markdown(f\"\"\"{g.message}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56e9a1f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>Hello, I am OpenBrain and ready to assist you with your request. Here is the JavaScript code to print \"Hello, World!\":\\n<code>javascript\\nconsole.log(\"Hello, World!\"); // prints \"Hello, World!\" in the console</code></p>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markdown.markdown(f\"\"\"{g.message}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dd77159-97cb-47bc-90a1-2d5bfcfa3a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base = '/home/linx/.cache/gpt4all'\n",
    "# MODELPATH = f\"{base}/ggml-gpt4all-j-v1.3-groovy.bin\"\n",
    "# mpt = gpt4all.GPT4All(MODELPATH, model_type='mpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65d573ce-84ad-431c-b77d-a4e6ff1ffe12",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "task = \"\"\n",
    "# You are OpenBrain, The prompt below is a question to answer, a task to complete, or a conversation to respond to; decide which and write an appropriate response.\n",
    "prompt = f\"\"\"\n",
    "### Instruction: \n",
    "You are OpenBrain, an AI managed by Mr. Phearum. Follow the user's instructions carefully. Markdown will be used to respond.\n",
    "### Prompt: \n",
    "{task}\n",
    "### Response:\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
